input {
  beats {
    port => 5044
  }
}

filter {
  # Grok 过滤器解析日志内容
  grok {
    match => { "message" => "\[%{TIMESTAMP_ISO8601:timestamp}\] %{WORD:service}\.%{WORD:level}: %{GREEDYDATA:message}" }
    add_tag => [ "grok_success" ]
  }

  # 提取日志文件名（从 file 输入插件获取的文件名）
  mutate {
    add_field => { "log_filename" => "%{[@metadata][path]}" }  # 添加原始文件路径作为字段
  }

  # 使用正则表达式从日志文件名中提取基本名称（如 video_fission 或 video_fission_result_upload_tos）
  ruby {
    code => "
      filename = event.get('log_filename')
      if filename
        match = filename.match(/([^\/]+)\/([^\/]+)$/)
        if match
          event.set('log_basename', match[2].split('-')[0])  # 提取基本名称
        end
      end
    "
  }

  # 使用 date 过滤器将 timestamp 字段转换为 @timestamp 字段
  date {
    match => ["timestamp", "ISO8601"]
    target => "@timestamp"
    timezone => "UTC"
    add_tag => [ "date_parsed" ]
  }

  # 错误日志的进一步处理 - 根据日志级别标记错误日志
  if [level]  == "ERROR" {
    mutate {
      add_field => { "log_severity" => "high" }  # 标记错误日志的严重性
      add_tag => [ "error_log" ]  # 给错误日志打标签
    }
  } else {
    mutate {
      add_field => { "log_severity" => "low" }   # 普通日志标记为低严重性
    }
  }

  # 解析日志中的 JSON 字段
  if [message] =~ /{.*}/ {
    json {
      source => "message"
      target => "json_parsed"
      add_tag => [ "json_parsed" ]
    }
  }

  # 为所有日志添加日志类型字段（用于区分不同的日志来源）
  mutate {
    add_field => { "log_type" => "laravel" }
  }

  # 去除一些不必要的字段（如果有）
  mutate {
    remove_field => [ "message" ]
  }
}

output {
  # 输出到 Elasticsearch，所有日志都存储在同一个索引
  elasticsearch {
    hosts => ["http://192.168.100.202:9200"]
    codec => "json"
    index => "sucai-%{+YYYY.MM}"
    workers => 1
  }

  # 输出到 stdout，便于调试
  stdout { codec => rubydebug }
}
